/**
 * Script de migration d'images vers Supabase Storage
 *
 * Fonctionnalit√©s :
 * - Optimise les images (WebP, max 1000px, qualit√© 80)
 * - Upload vers le bucket Supabase "products"
 * - G√©n√®re un rapport avec les URLs publiques
 * - G√©n√®re les requ√™tes SQL de mise √† jour
 *
 * S√âCURIT√â : Les fichiers sources ne sont JAMAIS modifi√©s ni supprim√©s
 *
 * Usage : node scripts/upload-images.js
 */

import fs from 'fs/promises'
import path from 'path'
import sharp from 'sharp'
import { createClient } from '@supabase/supabase-js'
import { fileURLToPath } from 'url'

// Configuration ESM pour __dirname
const __filename = fileURLToPath(import.meta.url)
const __dirname = path.dirname(__filename)

// ============================================
// CONFIGURATION
// ============================================

const CONFIG = {
  // Dossier source (relatif √† la racine du projet)
  sourceDir: path.resolve(__dirname, '../source_images'),

  // Bucket Supabase
  bucketName: 'products',

  // Dossier dans le bucket (optionnel, laisser vide pour la racine)
  bucketFolder: '',

  // Options d'optimisation
  image: {
    maxWidth: 1000,
    format: 'webp',
    quality: 80,
  },

  // Extensions support√©es
  supportedExtensions: ['.png', '.jpg', '.jpeg', '.gif', '.webp', '.tiff', '.bmp'],

  // Fichier de sortie SQL
  sqlOutputFile: path.resolve(__dirname, '../sql_update.txt'),

  // Fichier de rapport JSON
  reportFile: path.resolve(__dirname, '../upload_report.json'),
}

// ============================================
// SUPABASE CLIENT
// ============================================

function getSupabaseClient() {
  const supabaseUrl = process.env.VITE_SUPABASE_URL
  const supabaseKey = process.env.SUPABASE_SERVICE_ROLE_KEY || process.env.SUPABASE_ANON_KEY

  if (!supabaseUrl || !supabaseKey) {
    console.error('\n‚ùå Variables d\'environnement manquantes !')
    console.error('   Assurez-vous que VITE_SUPABASE_URL et SUPABASE_SERVICE_ROLE_KEY sont d√©finies.')
    console.error('\n   Options :')
    console.error('   1. Cr√©ez un fichier .env √† la racine du projet')
    console.error('   2. Ou lancez avec : VITE_SUPABASE_URL=xxx SUPABASE_SERVICE_ROLE_KEY=xxx node scripts/upload-images.js\n')
    process.exit(1)
  }

  return createClient(supabaseUrl, supabaseKey)
}

// ============================================
// UTILITAIRES
// ============================================

/**
 * Convertit un nom de fichier en slug URL-friendly
 * "BPC 157.png" -> "bpc-157"
 */
function slugify(filename) {
  // Enlever l'extension
  const nameWithoutExt = path.parse(filename).name

  return nameWithoutExt
    .toLowerCase()
    .normalize('NFD')
    .replace(/[\u0300-\u036f]/g, '') // Supprimer les accents
    .replace(/[^a-z0-9]+/g, '-')     // Remplacer les caract√®res sp√©ciaux par des tirets
    .replace(/^-+|-+$/g, '')         // Supprimer les tirets en d√©but/fin
    .replace(/-+/g, '-')             // √âviter les tirets multiples
}

/**
 * Formate la taille en bytes vers une cha√Æne lisible
 */
function formatSize(bytes) {
  if (bytes < 1024) return `${bytes} B`
  if (bytes < 1024 * 1024) return `${(bytes / 1024).toFixed(1)} KB`
  return `${(bytes / (1024 * 1024)).toFixed(2)} MB`
}

/**
 * Affiche une barre de progression
 */
function progressBar(current, total, width = 30) {
  const percent = current / total
  const filled = Math.round(width * percent)
  const empty = width - filled
  const bar = '‚ñà'.repeat(filled) + '‚ñë'.repeat(empty)
  return `[${bar}] ${current}/${total}`
}

// ============================================
// TRAITEMENT D'IMAGE
// ============================================

/**
 * Optimise une image avec Sharp
 * @returns {Buffer} Image optimis√©e en WebP
 */
async function optimizeImage(inputPath) {
  const image = sharp(inputPath)
  const metadata = await image.metadata()

  // Redimensionner seulement si l'image est plus large que maxWidth
  let pipeline = image
  if (metadata.width && metadata.width > CONFIG.image.maxWidth) {
    pipeline = pipeline.resize(CONFIG.image.maxWidth, null, {
      withoutEnlargement: true,
      fit: 'inside',
    })
  }

  // Convertir en WebP
  const optimizedBuffer = await pipeline
    .webp({ quality: CONFIG.image.quality })
    .toBuffer()

  return {
    buffer: optimizedBuffer,
    originalSize: (await fs.stat(inputPath)).size,
    optimizedSize: optimizedBuffer.length,
    originalWidth: metadata.width,
    originalHeight: metadata.height,
  }
}

// ============================================
// UPLOAD SUPABASE
// ============================================

/**
 * Upload un buffer vers Supabase Storage
 */
async function uploadToSupabase(supabase, buffer, filename) {
  const filePath = CONFIG.bucketFolder
    ? `${CONFIG.bucketFolder}/${filename}`
    : filename

  const { data, error } = await supabase.storage
    .from(CONFIG.bucketName)
    .upload(filePath, buffer, {
      contentType: 'image/webp',
      upsert: true, // Remplacer si existe d√©j√†
    })

  if (error) {
    throw new Error(`Upload failed: ${error.message}`)
  }

  // R√©cup√©rer l'URL publique
  const { data: urlData } = supabase.storage
    .from(CONFIG.bucketName)
    .getPublicUrl(filePath)

  return {
    path: data.path,
    publicUrl: urlData.publicUrl,
  }
}

// ============================================
// G√âN√âRATION DES FICHIERS DE SORTIE
// ============================================

/**
 * G√©n√®re le fichier SQL de mise √† jour
 */
async function generateSqlFile(results) {
  const lines = [
    '-- ==============================================',
    '-- Script SQL de mise √† jour des images produits',
    `-- G√©n√©r√© le ${new Date().toISOString()}`,
    '-- ==============================================',
    '',
    '-- ATTENTION : V√©rifiez les correspondances avant d\'ex√©cuter !',
    '-- Ce script suppose que le nom du fichier correspond au slug du produit.',
    '',
    'BEGIN;',
    '',
  ]

  for (const result of results) {
    if (result.success) {
      // Essayer de matcher avec le nom du produit
      const productSlug = result.slug
      lines.push(`-- Fichier source : ${result.originalFile}`)
      lines.push(`UPDATE products SET image_url = '${result.publicUrl}' WHERE slug = '${productSlug}';`)
      lines.push('')
    }
  }

  lines.push('-- V√©rification avant commit')
  lines.push('-- SELECT id, name, slug, image_url FROM products WHERE image_url LIKE \'%supabase%\';')
  lines.push('')
  lines.push('COMMIT;')
  lines.push('')
  lines.push('-- En cas de probl√®me : ROLLBACK;')

  await fs.writeFile(CONFIG.sqlOutputFile, lines.join('\n'), 'utf-8')
}

/**
 * G√©n√®re le rapport JSON
 */
async function generateJsonReport(results, stats) {
  const report = {
    generatedAt: new Date().toISOString(),
    stats,
    results: results.map(r => ({
      originalFile: r.originalFile,
      slug: r.slug,
      publicUrl: r.publicUrl || null,
      success: r.success,
      error: r.error || null,
      originalSize: r.originalSize,
      optimizedSize: r.optimizedSize,
      compressionRatio: r.originalSize
        ? `${((1 - r.optimizedSize / r.originalSize) * 100).toFixed(1)}%`
        : null,
    })),
  }

  await fs.writeFile(CONFIG.reportFile, JSON.stringify(report, null, 2), 'utf-8')
}

// ============================================
// SCRIPT PRINCIPAL
// ============================================

async function main() {
  console.log('\n‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó')
  console.log('‚ïë     üñºÔ∏è  Migration d\'images vers Supabase Storage          ‚ïë')
  console.log('‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù\n')

  // V√©rifier que le dossier source existe
  try {
    await fs.access(CONFIG.sourceDir)
  } catch {
    console.error(`‚ùå Dossier source introuvable : ${CONFIG.sourceDir}`)
    console.error('\n   Cr√©ez le dossier et placez-y vos images :')
    console.error(`   mkdir -p "${CONFIG.sourceDir}"\n`)
    process.exit(1)
  }

  // Lister les fichiers images
  const allFiles = await fs.readdir(CONFIG.sourceDir)
  const imageFiles = allFiles.filter(f =>
    CONFIG.supportedExtensions.includes(path.extname(f).toLowerCase())
  )

  if (imageFiles.length === 0) {
    console.error(`‚ùå Aucune image trouv√©e dans ${CONFIG.sourceDir}`)
    console.error(`   Extensions support√©es : ${CONFIG.supportedExtensions.join(', ')}\n`)
    process.exit(1)
  }

  console.log(`üìÅ Dossier source : ${CONFIG.sourceDir}`)
  console.log(`üì¶ Bucket cible   : ${CONFIG.bucketName}`)
  console.log(`üñºÔ∏è  Images trouv√©es : ${imageFiles.length}\n`)

  // Initialiser Supabase
  const supabase = getSupabaseClient()

  // V√©rifier que le bucket existe
  const { data: buckets, error: bucketsError } = await supabase.storage.listBuckets()
  if (bucketsError) {
    console.error(`‚ùå Erreur Supabase : ${bucketsError.message}`)
    process.exit(1)
  }

  const bucketExists = buckets.some(b => b.name === CONFIG.bucketName)
  if (!bucketExists) {
    console.error(`‚ùå Le bucket "${CONFIG.bucketName}" n'existe pas.`)
    console.error('   Cr√©ez-le dans le dashboard Supabase > Storage.\n')
    process.exit(1)
  }

  // Traitement des images
  console.log('üöÄ D√©but du traitement...\n')

  const results = []
  const stats = {
    total: imageFiles.length,
    success: 0,
    failed: 0,
    totalOriginalSize: 0,
    totalOptimizedSize: 0,
  }

  for (let i = 0; i < imageFiles.length; i++) {
    const file = imageFiles[i]
    const inputPath = path.join(CONFIG.sourceDir, file)
    const slug = slugify(file)
    const outputFilename = `${slug}.webp`

    process.stdout.write(`\r${progressBar(i + 1, imageFiles.length)} ${file.padEnd(30).slice(0, 30)}`)

    try {
      // 1. Optimiser l'image (en m√©moire, pas de modification du fichier source)
      const { buffer, originalSize, optimizedSize, originalWidth, originalHeight } =
        await optimizeImage(inputPath)

      stats.totalOriginalSize += originalSize
      stats.totalOptimizedSize += optimizedSize

      // 2. Upload vers Supabase
      const { publicUrl, path: uploadPath } = await uploadToSupabase(
        supabase,
        buffer,
        outputFilename
      )

      results.push({
        originalFile: file,
        slug,
        outputFilename,
        publicUrl,
        originalSize,
        optimizedSize,
        dimensions: `${originalWidth}x${originalHeight}`,
        success: true,
      })

      stats.success++

    } catch (error) {
      results.push({
        originalFile: file,
        slug,
        outputFilename,
        success: false,
        error: error.message,
        originalSize: 0,
        optimizedSize: 0,
      })

      stats.failed++
    }
  }

  console.log('\n\n')

  // G√©n√©rer les fichiers de sortie
  await generateSqlFile(results)
  await generateJsonReport(results, stats)

  // Afficher le rapport
  console.log('‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó')
  console.log('‚ïë                    üìä RAPPORT FINAL                       ‚ïë')
  console.log('‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù\n')

  console.log(`‚úÖ Succ√®s     : ${stats.success}/${stats.total}`)
  if (stats.failed > 0) {
    console.log(`‚ùå √âchecs     : ${stats.failed}/${stats.total}`)
  }
  console.log(`üì¶ Taille originale  : ${formatSize(stats.totalOriginalSize)}`)
  console.log(`üì¶ Taille optimis√©e  : ${formatSize(stats.totalOptimizedSize)}`)
  console.log(`üéØ Compression       : ${((1 - stats.totalOptimizedSize / stats.totalOriginalSize) * 100).toFixed(1)}%`)

  console.log('\nüìù URLs publiques g√©n√©r√©es :\n')
  console.log('‚îÄ'.repeat(70))

  for (const result of results) {
    if (result.success) {
      console.log(`  ${result.originalFile}`)
      console.log(`  ‚Üí ${result.publicUrl}`)
      console.log(`    (${formatSize(result.originalSize)} ‚Üí ${formatSize(result.optimizedSize)})`)
      console.log('')
    } else {
      console.log(`  ‚ùå ${result.originalFile}`)
      console.log(`     Erreur : ${result.error}`)
      console.log('')
    }
  }

  console.log('‚îÄ'.repeat(70))
  console.log(`\nüìÑ Fichier SQL g√©n√©r√© : ${CONFIG.sqlOutputFile}`)
  console.log(`üìÑ Rapport JSON       : ${CONFIG.reportFile}`)

  console.log('\n‚ú® Migration termin√©e !')
  console.log('‚ö†Ô∏è  N\'oubliez pas de v√©rifier le fichier SQL avant de l\'ex√©cuter.\n')

  // Code de sortie
  process.exit(stats.failed > 0 ? 1 : 0)
}

// Charger les variables d'environnement depuis .env si pr√©sent
async function loadEnv() {
  try {
    const envPath = path.resolve(__dirname, '../.env')
    const envContent = await fs.readFile(envPath, 'utf-8')

    for (const line of envContent.split('\n')) {
      const trimmed = line.trim()
      if (trimmed && !trimmed.startsWith('#')) {
        const [key, ...valueParts] = trimmed.split('=')
        const value = valueParts.join('=').replace(/^["']|["']$/g, '')
        if (key && value && !process.env[key]) {
          process.env[key] = value
        }
      }
    }
  } catch {
    // Pas de fichier .env, ce n'est pas grave
  }
}

// Point d'entr√©e
loadEnv().then(main).catch(error => {
  console.error('\n‚ùå Erreur fatale :', error.message)
  process.exit(1)
})
